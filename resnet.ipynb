{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로팅 라이브러리\n",
    "import matplotlib.pyplot as plt \n",
    "# 숫자 처리 라이브러리\n",
    "import numpy as np\n",
    "# 딥러닝을 위한 파이토치 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "# 토치비전 라이브러리\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "# 이미지 처리 라이브러리 (PIL, pillow)\n",
    "from PIL import Image\n",
    "# 주피터 노트북에서 plot이 보이도록 설정\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
    "data_dir = './data'\n",
    "vaild_size = 0.2\n",
    "\n",
    "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
    "t_transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor()\n",
    "])\n",
    "#convert image size to 224x224 for ResNet50 after crop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
    "print(t_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
    "# make train_data and test_data using datasets.ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "# 학습 데이터의 형식을 확인한다.\n",
    "print(train_data)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
    "split = int(np.floor(num_train * vaild_size))\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "print(train_idx)\n",
    "print(test_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "# 학습 loader와 테스트 loader의 class들을 출력하여 확인한다.\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드들을 묶어서 load_split_train_test() 함수를 만든다. (입력 : 데이터 디렉토리, 분할 비율) (출력 : 학습 데이터 로더, 테스트 데이터 로더)\n",
    "def load_split_train_test(data_dir, vaild_size):\n",
    "    t_transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor()])\n",
    "\n",
    "    train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "    indices = list(range(num_train))\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(np.floor(num_train * vaild_size))\n",
    "    train_idx, test_idx = indices[:split], indices[split:]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "    testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_split_train_test() 함수를 이용하여 trainloader와 testloader를 만들고 확인한다.\n",
    "trainloader, testloader = load_split_train_test(data_dir, 0.2)\n",
    "\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_images(num):\n",
    "    \n",
    "    data = datasets.ImageFolder(data_dir, transform= t_transforms)\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size = num)\n",
    "\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개의 이미지와 레이블을 랜덤하게 가져온다.\n",
    "images, labels = get_random_images(5)\n",
    "# 픽셀 배열을 PIL 형식의 이미지로 변환하고 이미지 크기를 지정한다.\n",
    "to_pil = transforms.ToPILImage()\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "\n",
    "\n",
    "# 학습 데이터의 class 리스트를 얻는다.\n",
    "classes = trainloader.dataset.classes\n",
    "\n",
    "# 이미지를 표시하기 위한 설정을 한다.\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    index = labels[ii].item()\n",
    "    sub.set_title(classes[index])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "# 주피터 노트북에 이미지를 표시한다.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute device를 정하고 확인한다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50 모델을 pretrained=True로 설정한다.\n",
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 신경망 구축 : 전이학습을 위해 모델의 가중치를 freeze 한다.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# 뉴런들을 연결하여 신경망을 생성한다.\n",
    "model.fc = nn.Sequential(nn.Linear(2048,512), nn.ReLU(),nn.Dropout(0.2),nn.Linear(512,2),nn.LogSoftmax(dim=1))\n",
    "\n",
    "\n",
    "# q: explain the above code\n",
    "# a: 2048개의 입력을 받아 512개의 출력을 내고, ReLU 함수를 거쳐 0.2의 확률로 Dropout을 적용한다.\n",
    "# 512개의 입력을 받아 2개의 출력을 내고, LogSoftmax 함수를 거쳐 1차원으로 변환한다.\n",
    "# 1차원으로 변환된 출력을 갖는 신경망을 생성한다.\n",
    "\n",
    "# 손실함수를 Cross entropy loss 함수로 지정한다.\n",
    "criterion = nn.NLLLoss()\n",
    "# why\n",
    "# optimizer를 Adam으로 지정한다.\n",
    "# what is Adam\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.03)\n",
    "\n",
    "# 신경망을 compute device로 보낸다.\n",
    "model.to(device)\n",
    "# 종료 여부를 출력한다.\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에폭 및 출력 간격을 설정한다.\n",
    "epochs = 5\n",
    "print_every = 10\n",
    "# 손실 변수들을 초기화 한다.\n",
    "running_loss = 0\n",
    "train_losses, test_losses = [], []\n",
    "# 현재의 학습 단계를 표현하는 steps 변수를 0으로 초기화 한다.\n",
    "steps = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정한 회수만큼 학습 후 테스트 및 평가해 본다.\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "\n",
    "        steps +=1\n",
    "        print('Training step' , steps)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "            print(\"Epoch {}/{}:\".format(epoch, epochs), \"Train loss: {:.3f}..\".format(running_loss/print_every),\"Test loss{:.3f}..\".format(test_loss/len(testloader)), \"Test accuracy: {:.3f}\\n\".format(accuracy/len(testloader)))\n",
    "\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "plt.plot(train_losses, label='training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "# in this graph, what is x-axis? y-axis?\n",
    "# x-axis: epoch\n",
    "# y-axis: loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
